{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    \n",
    "    ax1.plot(hist.history[\"accuracy\"])\n",
    "    ax1.plot(hist.history[\"val_accuracy\"])\n",
    "    ax1.set_title(\"model accuracy\")\n",
    "    ax1.set_ylabel(\"accuracy\")\n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    \n",
    "    ax2.plot(hist.history[\"loss\"])\n",
    "    ax2.plot(hist.history[\"val_loss\"])\n",
    "    ax2.set_title(\"model_loss\")\n",
    "    ax2.set_ylabel(\"loss\")\n",
    "    ax2.set_xlabel(\"epoch\")\n",
    "    fig.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds_name = 'stanford_dogs'\n",
    "img_size = 456\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def build_efficient(num_classes):\n",
    "    with strategy.scope():\n",
    "    \n",
    "        # Image augmentation\n",
    "        input = layers.Input(shape=(img_size,img_size,3))\n",
    "        x = img_augmentation(input)\n",
    "    \n",
    "        #Base pretrained model\n",
    "        base_model = EfficientNetB5(input_shape=(img_size, img_size,3) ,include_top=False, weights=\"imagenet\")\n",
    "        base_model.trainable = False\n",
    "        x = base_model(x)\n",
    "    \n",
    "        # Rebuild top\n",
    "        top_dropout_rate = 0.2\n",
    "        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "        output = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "        \n",
    "        model = Model(inputs=input,outputs=output)\n",
    "        # Compile\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "        model.compile(\n",
    "            optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train,info = tfds.load(tfds_name,split='train',shuffle_files=True,as_supervised=True,with_info=True)\n",
    "ds_val = tfds.load(tfds_name,split='test',shuffle_files=True,as_supervised=True)\n",
    "\n",
    "def load_and_preprocess_from_path_label(image, label):\n",
    "  return tf.image.resize(image,[img_size,img_size]), tf.one_hot(label,info.features['label'].num_classes )\n",
    "\n",
    "ds_train = ds_train.map(load_and_preprocess_from_path_label)\n",
    "ds_val = ds_val.map(load_and_preprocess_from_path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_batch_train = ds_train.batch(batch_size=batch_size, drop_remainder=False)\n",
    "ds_batch_train = ds_batch_train.prefetch(tf.data.AUTOTUNE)\n",
    "ds_batch_val = ds_val.batch(batch_size=batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_efficient(num_classes=info.features['label'].num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "hist = model.fit(ds_batch_train, epochs=epochs, validation_data=ds_batch_val,batch_size=batch_size, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./trained_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Oct 18 2022, 18:57:03) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6e0a1c10175477e1abd446a0de805bd8223d984036a7e39d1f0cd05f000638c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
